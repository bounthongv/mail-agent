# Scheduling
schedule:
  enabled: true
  interval_hours: 1

# AI Settings
ai:
  provider: "ollama"
  model: "kimi-k2.5:cloud"
  max_tokens: 300
  temperature: 0.3

# Local AI / Notebook Settings
localai:
  enabled: true
  provider: "ollama"
  # Primary: Windows Server (Fastest)
  model: "kimi-k2.5:cloud"
  url: "http://209.126.1.13:11434/api/generate"
  
  # Secondary: Ubuntu Server (Fallback)
  secondary_url: "http://202.137.147.5:11434/api/generate"
  secondary_model: "glm-4.6:cloud"

# Report Settings
report:
  daily_summary: true
  max_emails_per_report: 20
